{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3sNKZq4XrXQh"
   },
   "source": [
    "# <font color='red'><b>Bootstrap assignment</b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RAHap1Z3FZC-"
   },
   "source": [
    "<b>There will be some functions that start with the word \"grader\" ex: grader_sampples(), grader_30().. etc, you should not change those function definition.\n",
    "\n",
    "Every Grader function has to return True.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cuxBq_bvrwh2"
   },
   "source": [
    "<font color='blue'> <b>Importing packages</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m6ag91ijrQOs"
   },
   "outputs": [],
   "source": [
    "import numpy as np # importing numpy for numerical computation\n",
    "from sklearn.datasets import load_boston # here we are using sklearn's boston dataset\n",
    "from sklearn.metrics import mean_squared_error # importing mean_squared_error metric\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CcHOsONTt1K_"
   },
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "x=boston.data #independent variables\n",
    "y=boston.target #target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pc1htEFYuLRj",
    "outputId": "f5b60712-98b3-4cdc-b629-3546c1e3859c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "kQle3T_wuOa3",
    "outputId": "521c7bdd-5316-48d5-c534-b61d170d2c28"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.3200e-03, 1.8000e+01, 2.3100e+00, 0.0000e+00, 5.3800e-01,\n",
       "        6.5750e+00, 6.5200e+01, 4.0900e+00, 1.0000e+00, 2.9600e+02,\n",
       "        1.5300e+01, 3.9690e+02, 4.9800e+00],\n",
       "       [2.7310e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01,\n",
       "        6.4210e+00, 7.8900e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02,\n",
       "        1.7800e+01, 3.9690e+02, 9.1400e+00],\n",
       "       [2.7290e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01,\n",
       "        7.1850e+00, 6.1100e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02,\n",
       "        1.7800e+01, 3.9283e+02, 4.0300e+00],\n",
       "       [3.2370e-02, 0.0000e+00, 2.1800e+00, 0.0000e+00, 4.5800e-01,\n",
       "        6.9980e+00, 4.5800e+01, 6.0622e+00, 3.0000e+00, 2.2200e+02,\n",
       "        1.8700e+01, 3.9463e+02, 2.9400e+00],\n",
       "       [6.9050e-02, 0.0000e+00, 2.1800e+00, 0.0000e+00, 4.5800e-01,\n",
       "        7.1470e+00, 5.4200e+01, 6.0622e+00, 3.0000e+00, 2.2200e+02,\n",
       "        1.8700e+01, 3.9690e+02, 5.3300e+00]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AEa_HqRZloH4"
   },
   "source": [
    "## <font color='red'><b>Task 1</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YQ5q8IxHNRk3"
   },
   "source": [
    "<font color='red'> <b>Step - 1</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GJCFCaOzl7Mr"
   },
   "source": [
    "*  <font color='blue'><b>Creating samples</b></font><br>\n",
    "    <b> Randomly create 30 samples from the whole boston data points</b>\n",
    "    *  Creating each sample: Consider any random 303(60% of 506) data points from whole data set and then replicate any 203 points from the sampled points\n",
    "    \n",
    "     For better understanding of this procedure lets check this examples, assume we have 10 data points [1,2,3,4,5,6,7,8,9,10], first we take 6 data points randomly , consider we have selected [4, 5, 7, 8, 9, 3] now we will replicate 4 points from [4, 5, 7, 8, 9, 3], consder they are [5, 8, 3,7] so our final sample will be [4, 5, 7, 8, 9, 3, 5, 8, 3,7]\n",
    "* <font color='blue'><b> Create 30 samples </b></font>\n",
    "    *  Note that as a part of the Bagging when you are taking the random samples <b>make sure each of the sample will have different set of columns</b><br>\n",
    "Ex: Assume we have 10 columns[1 ,2 ,3 ,4 ,5 ,6 ,7 ,8 ,9 ,10] for the first sample we will select [3, 4, 5, 9, 1, 2] and for the second sample  [7, 9, 1, 4, 5, 6, 2] and so on...\n",
    "Make sure each sample will have atleast 3 feautres/columns/attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zUqFEBSvNjCa"
   },
   "source": [
    "<font color='red'><b>Step - 2 </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uqi9AhCYNq3Z"
   },
   "source": [
    "<font color='blue'><b>Building High Variance Models on each of the sample and finding train MSE value</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-lLBnZHXOFln"
   },
   "source": [
    "*  Build a regression trees on each of 30 samples.\n",
    "*  Computed the predicted values of each data point(506 data points) in your corpus.\n",
    "*  Predicted house price of $i^{th}$ data point $y^{i}_{pred} =  \\frac{1}{30}\\sum_{k=1}^{30}(\\text{predicted value of } x^{i} \\text{ with } k^{th} \\text{ model})$\n",
    "*  Now calculate the $MSE =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kls23JLnSN23"
   },
   "source": [
    "<font color='red'> <b>Step - 3 </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rz2GchkGSWnh"
   },
   "source": [
    "*  <font color='blue'><b>Calculating the OOB score </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DGHkVV2kSibm"
   },
   "source": [
    "*  Predicted house price of $i^{th}$ data point $y^{i}_{pred} =  \\frac{1}{k}\\sum_{\\text{k= model which was buit on samples not included } x^{i}}(\\text{predicted value of } x^{i} \\text{ with } k^{th} \\text{ model})$.\n",
    "*  Now calculate the $OOB Score =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RK860ocxTyoz"
   },
   "source": [
    "# <font color='red'><b>Task 2</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1dme-N6TUCrY"
   },
   "source": [
    "*  <font color='blue'><b>Computing CI of OOB Score and Train MSE</b></font>\n",
    "  *   Repeat Task 1 for 35 times, and for each iteration store the Train MSE and OOB score </li>\n",
    "<li> After this we will have 35 Train MSE values and 35 OOB scores </li>\n",
    "<li> using these 35 values (assume like a sample) find the confidence intravels of MSE and OOB Score </li>\n",
    "<li> you need to report CI of MSE and CI of OOB Score </li>\n",
    "<li> Note: Refer the Central_Limit_theorem.ipynb to check how to find the confidence intravel</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O6UcH1x9Uwrj"
   },
   "source": [
    "# <font color='red'><b>Task 3</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bOC_AgsLU7OH"
   },
   "source": [
    "*  <font color='blue'><b>Given a single query point predict the price of house.</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HYs5jSFdVILe"
   },
   "source": [
    "Consider xq= [0.18,20.0,5.00,0.0,0.421,5.60,72.2,7.95,7.0,30.0,19.1,372.13,18.60] \n",
    "Predict the house price for this point as mentioned in the step 2 of Task 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_6gxZEsFWm-8"
   },
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V2fHTdS_zpgG"
   },
   "source": [
    "# <font color='blue'> <b>Task - 1</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e0yGBuryOwHz"
   },
   "source": [
    "<font color='blue'><b>Step - 1</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lJXX8vf3z073"
   },
   "source": [
    "*  <font color='blue'> <b>Creating samples</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CSVaWG1F4uCZ"
   },
   "source": [
    "<font color='Orange'><b>Algorithm</b></font>\n",
    "\n",
    "![alt text](https://i.imgur.com/BTVYXQ1.jpg/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f_oWoN97BhDY"
   },
   "source": [
    "*  <font color='blue'><b> Write code for generating samples</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ph_6D2SDzz7F"
   },
   "outputs": [],
   "source": [
    "def generating_samples(input_data, target_data):\n",
    "\n",
    "    '''In this function, we will write code for generating 30 samples '''\n",
    "    # you can use random.choice to generate random indices without replacement\n",
    "    # Please have a look at this link https://docs.scipy.org/doc/numpy-1.16.0/reference/generated/numpy.random.choice.html for more details\n",
    "    # Please follow above pseudo code for generating samples \n",
    "    \n",
    "\n",
    "    # return sampled_input_data , sampled_target_data,selected_rows,selected_columns\n",
    "    #note please return as lists\n",
    "    \n",
    "    selecting_rows = np.random.choice(input_data.shape[0], round(0.6 * input_data.shape[0]) - 1, replace = False)\n",
    "    replacing_rows = np.random.choice(selecting_rows, round(0.4 * input_data.shape[0]) + 1, replace = False)\n",
    "    selecting_columns = np.random.choice(13, 3, replace = False)\n",
    "    \n",
    "    sample_data = input_data[selecting_rows[:, None], selecting_columns]\n",
    "    target_of_sample_data = target_data[selecting_rows]\n",
    "    \n",
    "    replicated_sample_data = input_data[replacing_rows[:, None], selecting_columns]\n",
    "    target_of_replicated_sample_data = target_data[replacing_rows]\n",
    "    \n",
    "    final_sample_data = np.vstack((sample_data, replicated_sample_data))\n",
    "    final_target_data = np.vstack((target_of_sample_data.reshape(-1,1), target_of_replicated_sample_data.reshape(-1,1)))\n",
    "    \n",
    "    return final_sample_data, final_target_data, selecting_rows, selecting_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MivEQFlm7iOg"
   },
   "source": [
    "<font color='cyan'> <b> Grader function - 1 </b> </fongt>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AVvuhNzm7uld"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_samples(a,b,c,d):\n",
    "    length = (len(a)==506  and len(b)==506)\n",
    "    sampled = (len(a)-len(set([str(i) for i in a]))==203)\n",
    "    rows_length = (len(c)==303)\n",
    "    column_length= (len(d)>=3)\n",
    "    assert(length and sampled and rows_length and column_length)\n",
    "    return True\n",
    "a,b,c,d = generating_samples(x, y)\n",
    "grader_samples(a,b,c,d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b4LSsmn4Jn2_"
   },
   "source": [
    "*  <font color='blue'> <b>Create 30 samples </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3ec7MN6sL2BZ"
   },
   "source": [
    "![alt text](https://i.imgur.com/p8eZaWL.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XXlKWjCcBvTk"
   },
   "outputs": [],
   "source": [
    "# Use generating_samples function to create 30 samples \n",
    "# store these created samples in a list\n",
    "list_input_data =[]\n",
    "list_output_data =[]\n",
    "list_selected_row= []\n",
    "list_selected_columns=[]\n",
    "\n",
    "for i in range(30):\n",
    "    a, b, c, d = generating_samples(x, y)\n",
    "    list_input_data.append(a)\n",
    "    list_output_data.append(b)\n",
    "    list_selected_row.append(c)\n",
    "    list_selected_columns.append(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MXUz9VFiMQkh"
   },
   "source": [
    "<font color='cyan'> <b>Grader function - 2 </b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hCvIq8NuMWOC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_30(a):\n",
    "    assert(len(a)==30 and len(a[0])==506)\n",
    "    return True\n",
    "grader_30(list_input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Pv-mkZkO6dh"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "whaHCPB0O8qF"
   },
   "source": [
    "<font color='red'><b>Step - 2 </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XBy4zXSWPtU8"
   },
   "source": [
    "<font color='orange'><b>Flowchart for building tree</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5xvH06HPQBdP"
   },
   "source": [
    "![alt text](https://i.imgur.com/pcXfSmp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WRwPO_uHQjul"
   },
   "source": [
    "*  <font color='blue'><b> Write code for building regression trees</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YWQp6tRwMthq"
   },
   "outputs": [],
   "source": [
    "def buildDecisionTree(inputX, inputY):\n",
    "    \n",
    "    \"\"\"This function creates and fits decision tree regressor with input train X and Y\"\"\"\n",
    "    tree = DecisionTreeRegressor(max_depth = None)\n",
    "    tree.fit(inputX, inputY)\n",
    "    \n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List 30 decision trees\n",
    "decisionTrees = []\n",
    "\n",
    "for i in range(len(list_input_data)):\n",
    "    decisionTrees.append(buildDecisionTree(list_input_data[i], list_output_data[i]))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "21j8BKfAQ1U8"
   },
   "source": [
    "<font color='orange'><b>Flowchart for calculating MSE </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Q0mTBD2RBx_"
   },
   "source": [
    "![alt text](https://i.imgur.com/sPEE618.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6e-UamlHRjPy"
   },
   "source": [
    "After getting predicted_y for each data point, we can use sklearns mean_squared_error to calculate the MSE between predicted_y and actual_y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TnIMT7_oR312"
   },
   "source": [
    "*  <font color='blue'><b> Write code for calculating MSE</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_Y_of_datapoint(y_pred):\n",
    "    \n",
    "    \"\"\"This function gives the median of all predicted Y values for each point\"\"\"\n",
    "    \n",
    "    # Take transpose of y_pred to make array of shape (506, 30) and sort the array\n",
    "    # For each data point, sort all 30 y_pred values to compute median\n",
    "    y_pred = np.transpose(np.array(y_pred))\n",
    "    y_pred = np.sort(y_pred)\n",
    "    predicted_y_values = []\n",
    "    \n",
    "    # Compute median on each y_pred value and make a list\n",
    "    for i in range(len(y_pred)):\n",
    "        predicted_y_values.append(np.median(y_pred[i]))\n",
    "    \n",
    "    return np.array(predicted_y_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qWhcvMRWRA9b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2294410439074737"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict Y values with all 30 decision trees and compute MSE\n",
    "def computeMSE(input_x, input_y, decisionTrees, list_selected_columns):\n",
    "    \"\"\"This function takes input X and predicts Y pred using random forest and returns MSE\"\"\"\n",
    "    \n",
    "    array_of_y = []\n",
    "\n",
    "    for i in range(len(list_selected_columns)):\n",
    "        array_of_y.append(decisionTrees[i].predict(input_x[:, list_selected_columns[i]]))\n",
    "\n",
    "    predict_y_datapoints = predict_Y_of_datapoint(array_of_y) \n",
    "\n",
    "    return mean_squared_error(input_y, predict_y_datapoints)\n",
    "\n",
    "computeMSE(x, y, decisionTrees, list_selected_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RuclPDMnSz8F"
   },
   "source": [
    "<font color='blue'><b>Step - 3 </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ESb9FSIDTM5V"
   },
   "source": [
    "<font color='orange'><b>Flowchart for calculating OOB score</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HB-d6NMETbd9"
   },
   "source": [
    "![alt text](https://i.imgur.com/95S5Mtm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WW3GOcFzTqbt"
   },
   "source": [
    "Now calculate the $OOB Score =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zBqcS03pUYSZ"
   },
   "source": [
    "*  <font color='blue'><b> Write code for calculating OOB score </b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fog_6DNdS-h_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.451222705657134"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get oobs predicted y value and compute obb score\n",
    "def getOob_Y_pred(input_x, input_y, decisionTrees, list_input_data, list_selected_columns):\n",
    "    \n",
    "    \"\"\"This function checks each point in input dataset with each input sample and \n",
    "    predicts y value with respective decision tree if the sample doesnt contain the data point\"\"\"\n",
    "    \n",
    "    y_preds = []\n",
    "    \n",
    "    # Check for each point\n",
    "    for i in range(len(input_x)):\n",
    "        y_preds_datapoint = []\n",
    "        \n",
    "        # Check datapoint in each sample\n",
    "        for j in range(len(list_selected_columns)):\n",
    "            datapoint = input_x[i, list_selected_columns[j]].reshape(-1, 3)\n",
    "            sample_array = list_input_data[j]\n",
    "\n",
    "            #https://stackoverflow.com/questions/33217660/checking-if-a-numpy-array-contains-another-array\n",
    "            if (not (sample_array == datapoint).all(1).any()):\n",
    "                # Use the model as the model has not been trained with this data point\n",
    "                y_preds_datapoint.append(decisionTrees[j].predict(datapoint))\n",
    "\n",
    "        y_preds.append(y_preds_datapoint)\n",
    "     \n",
    "    oob_y_pred = []\n",
    "    for y_pred_val in y_preds:\n",
    "        oob_y_pred.append(np.median(np.sort(np.array(y_pred_val))))\n",
    "\n",
    "    oob_score = 0\n",
    "    for i in range(x.shape[0]):\n",
    "        oob_score += ((input_y[i] - oob_y_pred[i]) ** 2)\n",
    "    oob_score /=  x.shape[0]\n",
    "        \n",
    "    return oob_score\n",
    "\n",
    "getOob_Y_pred(x,y, decisionTrees, list_input_data, list_selected_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sbuiwX3OUjUI"
   },
   "source": [
    "# <font color='blue'><b>Task 2</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ceW5-D88Uswi"
   },
   "outputs": [],
   "source": [
    "MSE_list = []\n",
    "Oob_scores = []\n",
    "for itr in range(35):\n",
    "    \n",
    "    # Build sample lists\n",
    "    list_input_data =[]\n",
    "    list_output_data =[]\n",
    "    list_selected_row= []\n",
    "    list_selected_columns=[]\n",
    "\n",
    "    for i in range(30):\n",
    "        a, b, c, d = generating_samples(x, y)\n",
    "        list_input_data.append(a)\n",
    "        list_output_data.append(b)\n",
    "        list_selected_row.append(c)\n",
    "        list_selected_columns.append(d)\n",
    "    \n",
    "    # Build decision trees with samples\n",
    "    decisionTrees = []\n",
    "\n",
    "    for i in range(len(list_input_data)):\n",
    "        decisionTrees.append(buildDecisionTree(list_input_data[i], list_output_data[i])) \n",
    "\n",
    "    # Copute MSE\n",
    "    MSE_list.append(computeMSE(x, y, decisionTrees, list_selected_columns))\n",
    "    Oob_scores.append(getOob_Y_pred(x,y, decisionTrees, list_input_data, list_selected_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 10 samples out of MSE_list and Oob_scores values and compute CI\n",
    "\n",
    "def getCI(population):\n",
    "    x = PrettyTable([\"#samples\", \"Sample Size\", \"Sample mean\", \"Left C.I\",\"Right C.I\",\"Pop mean\",\"Catch\"])\n",
    "    population = np.array(population)\n",
    "    population_mean = np.mean(population)\n",
    "    \n",
    "    # Make 10 samples with size 5 and compute CI for all of them\n",
    "    for i in range(10):\n",
    "        sample=population[np.random.choice(population.shape[0], 10)]\n",
    "        sample_mean = sample.mean()\n",
    "        sample_std =  sample.std()\n",
    "        sample_size = len(sample)\n",
    "        # here we are using sample standard deviation instead of population standard deviation \n",
    "        # Assume we dont know the std-dev of population\n",
    "        left_limit  = np.round(sample_mean - 2*(sample_std/np.sqrt(sample_size)), 3)\n",
    "        right_limit = np.round(sample_mean + 2*(sample_std/np.sqrt(sample_size)), 3)\n",
    "        catch = (population_mean <= right_limit) and (population_mean >= left_limit)\n",
    "        \n",
    "        row = []\n",
    "        row.append(i+1)\n",
    "        row.append(sample_size)\n",
    "        row.append(sample_mean)\n",
    "        row.append(left_limit)\n",
    "        row.append(right_limit)\n",
    "        row.append(population_mean)\n",
    "        row.append(catch)\n",
    "        x.add_row(row)\n",
    "    print(x)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+----------+-----------+--------------------+-------+\n",
      "| #samples | Sample Size |    Sample mean     | Left C.I | Right C.I |      Pop mean      | Catch |\n",
      "+----------+-------------+--------------------+----------+-----------+--------------------+-------+\n",
      "|    1     |      10     | 1.3302084874400006 |  0.705   |   1.955   | 1.3294221171017317 |  True |\n",
      "|    2     |      10     | 1.4456273671130953 |  0.614   |   2.277   | 1.3294221171017317 |  True |\n",
      "|    3     |      10     | 1.6415383065557136 |  0.793   |    2.49   | 1.3294221171017317 |  True |\n",
      "|    4     |      10     | 1.0305529240176503 |  0.652   |   1.409   | 1.3294221171017317 |  True |\n",
      "|    5     |      10     | 1.0939774262592388 |  0.421   |   1.767   | 1.3294221171017317 |  True |\n",
      "|    6     |      10     | 2.157554853385859  |  1.217   |   3.098   | 1.3294221171017317 |  True |\n",
      "|    7     |      10     | 0.9620705174654619 |  0.359   |   1.565   | 1.3294221171017317 |  True |\n",
      "|    8     |      10     | 1.443417902445675  |  0.757   |   2.129   | 1.3294221171017317 |  True |\n",
      "|    9     |      10     | 1.3334081512318146 |  0.678   |   1.988   | 1.3294221171017317 |  True |\n",
      "|    10    |      10     | 1.0779784292085186 |  0.558   |   1.598   | 1.3294221171017317 |  True |\n",
      "+----------+-------------+--------------------+----------+-----------+--------------------+-------+\n"
     ]
    }
   ],
   "source": [
    "getCI(MSE_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+----------+-----------+--------------------+-------+\n",
      "| #samples | Sample Size |    Sample mean     | Left C.I | Right C.I |      Pop mean      | Catch |\n",
      "+----------+-------------+--------------------+----------+-----------+--------------------+-------+\n",
      "|    1     |      10     | 26.88152480584434  |  23.953  |   29.81   | 26.296265514629887 |  True |\n",
      "|    2     |      10     | 25.542205284596214 |  22.421  |   28.664  | 26.296265514629887 |  True |\n",
      "|    3     |      10     | 26.161440749986134 |  24.59   |   27.733  | 26.296265514629887 |  True |\n",
      "|    4     |      10     | 26.999307758550593 |  24.94   |   29.059  | 26.296265514629887 |  True |\n",
      "|    5     |      10     | 25.99267288116721  |  23.308  |   28.678  | 26.296265514629887 |  True |\n",
      "|    6     |      10     | 27.96396922553409  |  25.371  |   30.557  | 26.296265514629887 |  True |\n",
      "|    7     |      10     | 27.16238928563642  |  24.969  |   29.356  | 26.296265514629887 |  True |\n",
      "|    8     |      10     | 26.700793818013928 |  25.068  |   28.334  | 26.296265514629887 |  True |\n",
      "|    9     |      10     | 26.772193668894243 |  24.184  |   29.36   | 26.296265514629887 |  True |\n",
      "|    10    |      10     | 27.039670106796414 |  24.733  |   29.346  | 26.296265514629887 |  True |\n",
      "+----------+-------------+--------------------+----------+-----------+--------------------+-------+\n"
     ]
    }
   ],
   "source": [
    "getCI(Oob_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jKTnJdiBVS_e"
   },
   "source": [
    "# <font color='blue'><b>Task 3</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eXxrvZqHV1Fr"
   },
   "source": [
    "<font color='orange'><b>Flowchart for Task 3</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NyjwEJ62V6a6"
   },
   "source": [
    "<b>Hint: </b> We created 30 models by using 30 samples in TASK-1. Here, we need send query point \"xq\"  to 30 models and perform the regression on the output generated by 30 models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0emSwLL7VurD"
   },
   "source": [
    "![alt text](https://i.imgur.com/Y5cNhQk.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "29hjwKlWWDfo"
   },
   "source": [
    "*  <font color='blue'><b> Write code for TASK 3 </b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i_pUlSD-VYD1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.95\n"
     ]
    }
   ],
   "source": [
    "# Compute Yq for input Xq with implemented random forest\n",
    "yq_preds_30 = []\n",
    "xq = np.array([0.18, 20.0, 5.00, 0.0, 0.421, 5.60, 72.2, 7.95, 7.0, 30.0, 19.1, 372.13, 18.60])\n",
    "\n",
    "for i in range(len(list_selected_columns)):\n",
    "    yq_preds_30.append(decisionTrees[i].predict(xq[list_selected_columns[i]].reshape(-1, 3)))\n",
    "\n",
    "yq_pred = predict_Y_of_datapoint(yq_preds_30) \n",
    "print(yq_pred[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DJHTGEZgWJjR"
   },
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IOdUi-0xWOJ9"
   },
   "source": [
    "<font color='red'><b>Write observations for task 1, task 2, task 3 indetail</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AIcax45hWKT-"
   },
   "source": [
    "Task 1:\n",
    "\n",
    "With bagging, we are getting very less MSE error as we are using high variance base models resulting very less error in training data. The CV error/ Oob score is 28.451. We can try with different number of decision trees and try to reduce the error. But the training MSE is very low 1.229 as we are training and predicting with same dataset.\n",
    "\n",
    "Task 2:\n",
    "\n",
    "Here the population and sample mean similar and with Std-dev of samples, we are calculating confidence interval of population mean. Means within the left and right interval, mean can exist in 95% of the points in that interval. We are using the 2nd std-dev value from mean. We have seen, mean actually lies within that range.\n",
    "\n",
    "Task 3:\n",
    "\n",
    "We are successfully predicting value for query point Xq.\n",
    "\n",
    "Here while aggregating, we are using median instead of mean."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Bootstrap_assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
